{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "U4Cowq5TXGAD"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "n_try = 1"
      ],
      "metadata": {
        "id": "7eQpWw03aywp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "j8yGVvCIhl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47959cf3-7eb0-430a-fa15-b15dbb034116"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os.path import isdir\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import L1L2\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "w0hvr7aeiAML"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "U4Cowq5TXGAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DataProperties:\n",
        "    main_dir = '/content/drive/MyDrive/ML/Datasets/4.Food5k/'\n",
        "    validation_dir = main_dir + 'validation/'\n",
        "    train_dir = main_dir + 'train/'\n",
        "    test_dir = main_dir + 'test/'\n",
        "\n",
        "    hackathon_dir = f'/content/drive/MyDrive/ML/Unox/{n_try}/'\n",
        "    model_save_dir = hackathon_dir + 'Models/'\n",
        "    histories_dir = hackathon_dir + 'Histories/'\n",
        "\n",
        "\n",
        "def make_dirs(dirs):\n",
        "    for dir in dirs:\n",
        "        if not isdir(dir):\n",
        "            os.mkdir(dir)\n",
        "\n",
        "\n",
        "make_dirs(\n",
        "    [\n",
        "     DataProperties.hackathon_dir,\n",
        "     DataProperties.train_dir,\n",
        "     DataProperties.validation_dir,\n",
        "     DataProperties.model_save_dir,\n",
        "     DataProperties.histories_dir,\n",
        "    ]\n",
        ")\n",
        "\n",
        "assert(isdir(DataProperties.main_dir))\n",
        "assert(isdir(DataProperties.model_save_dir))\n",
        "\n",
        "assert(isdir(DataProperties.train_dir))\n",
        "assert(isdir(DataProperties.validation_dir))\n",
        "assert(isdir(DataProperties.histories_dir))"
      ],
      "metadata": {
        "id": "hq0-keuoiHju"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_files(directory):\n",
        "    total_files = 0\n",
        "\n",
        "    for base, _, files in os.walk(directory):\n",
        "        # print('Searching in : ',base)\n",
        "        for _ in files:\n",
        "            total_files += 1\n",
        "    return total_files\n",
        "\n",
        "x = ['T', 'V', 'Test']\n",
        "y = [\n",
        "     calc_files(dir) for dir in [\n",
        "                                 DataProperties.train_dir, DataProperties.validation_dir,\n",
        "                                 DataProperties.test_dir]\n",
        "]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(x, y, width = 0.75, color = 'blue')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "-BAUq3oaSgY2",
        "outputId": "9ee0d57f-e6f1-425b-d2f2-27e103f68bef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_shape = (256, 256)\n",
        "\n",
        "train_batch_size = 8\n",
        "\n",
        "width_shift_range = 0.09\n",
        "height_shift_range = 0.09\n",
        "rotation_range = 0.2\n",
        "zoom_range = [0.9, 1.1]"
      ],
      "metadata": {
        "id": "4QjgwG7vUOze"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_use = 1\n",
        "\n",
        "def preprocess(image):\n",
        "    image = image / 255.\n",
        "    return image\n",
        "\n",
        "train_generator = ImageDataGenerator(\n",
        "    validation_split = 1 - train_use,\n",
        "\n",
        "    preprocessing_function = preprocess,\n",
        "    # samplewise_center = \n",
        "    # featurewise_center = \n",
        "\n",
        "    width_shift_range = width_shift_range,\n",
        "    height_shift_range = height_shift_range,\n",
        "    rotation_range = rotation_range,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "\n",
        "    # brightness_range = \n",
        "    zoom_range = zoom_range\n",
        ")\n",
        "\n",
        "train_flow = train_generator.flow_from_directory(\n",
        "    directory = DataProperties.train_dir,\n",
        "\n",
        "    target_size = target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    # classes = \n",
        "    class_mode = 'sparse',\n",
        "    batch_size = train_batch_size,\n",
        "    subset = 'training',\n",
        "    shuffle = True,\n",
        "    seed = 123\n",
        ")\n",
        "\n",
        "print(f'Use {train_flow.n} images for train flow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT9BQJWFTmP8",
        "outputId": "d178d374-c975-4275-efa9-4d120a60d851"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1031 images belonging to 2 classes.\n",
            "Use 1031 images for train flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_use = 1  # 0.4\n",
        "\n",
        "val_generator = ImageDataGenerator(\n",
        "    validation_split = 1 - val_use,\n",
        "\n",
        "    preprocessing_function = preprocess,\n",
        "    # samplewise_center = \n",
        "    # featurewise_center = \n",
        "\n",
        "    width_shift_range = width_shift_range,\n",
        "    height_shift_range = height_shift_range,\n",
        "    rotation_range = rotation_range,\n",
        "    horizontal_flip = True,\n",
        "    vertical_flip = True,\n",
        "\n",
        "    # brightness_range = \n",
        "    zoom_range = zoom_range\n",
        ")\n",
        "\n",
        "val_flow = val_generator.flow_from_directory(\n",
        "    directory = DataProperties.validation_dir,\n",
        "\n",
        "    target_size = target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    # classes = \n",
        "    class_mode = 'sparse',\n",
        "    # batch_size = None,\n",
        "    subset = 'training',\n",
        "    shuffle = False,\n",
        "    seed = 123\n",
        ")\n",
        "\n",
        "print(f'Use {val_flow.n} images for validation flow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i26GaljUlLt",
        "outputId": "faa5366a-3d9b-4495-92a4-893a8f279eae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 475 images belonging to 2 classes.\n",
            "Use 475 images for validation flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_use = 1\n",
        "\n",
        "test_generator = ImageDataGenerator(\n",
        "    validation_split = 1 - test_use,\n",
        "\n",
        "    preprocessing_function = preprocess,\n",
        "    # samplewise_center = \n",
        "    # featurewise_center = \n",
        "\n",
        "    # width_shift_range = 2,\n",
        "    # height_shift_range = 2,\n",
        "    # rotation_range = 0.5,\n",
        "    # horizontal_flip = True,\n",
        "    # vertical_flip = True,\n",
        "\n",
        "    # brightness_range = \n",
        "    # zoom_range = [-0.2, 0.2]\n",
        ")\n",
        "\n",
        "test_flow = test_generator.flow_from_directory(\n",
        "    directory = DataProperties.test_dir,\n",
        "\n",
        "    target_size = target_shape,\n",
        "    color_mode = 'rgb',\n",
        "    # classes = \n",
        "    class_mode = 'sparse',\n",
        "    # batch_size = None,\n",
        "    subset = 'training',\n",
        "    shuffle = False,\n",
        "    seed = 123\n",
        ")\n",
        "\n",
        "print(f'Use {test_flow.n} images for test flow')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IONsaaYNVBiL",
        "outputId": "0aa172a7-f7bb-4b8f-a4cd-02127b20e9d9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "Use 40 images for test flow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(batch, labels, n_subplots, class_indices, figsize = (15, 15)):\n",
        "    plt.figure(figsize = figsize)\n",
        "    for i in range(n_subplots): #(batch_size):\n",
        "        ax = plt.subplot(\n",
        "            int(np.sqrt(n_subplots)), \n",
        "            int(np.sqrt(n_subplots)), \n",
        "            i + 1\n",
        "        )\n",
        "        plt.imshow(batch[i])\n",
        "        plt.title(labels[i])\n",
        "        # plt.title(get_class_name(class_indices, labels[i]))\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "\n",
        "def visualize_flow(n, flow):\n",
        "\n",
        "    how_many_to_show = n\n",
        "    # flow = train_flow\n",
        "    for _ in range(1):\n",
        "        batch, labels = flow.next()\n",
        "        print(batch.shape, np.max(batch))\n",
        "        assert np.max(batch) <= 1.01\n",
        "        assert np.min(batch) >= 0.0\n",
        "        \n",
        "        visualize(\n",
        "            batch,\n",
        "            labels,\n",
        "            how_many_to_show,\n",
        "            class_indices = flow.class_indices,\n",
        "            figsize=(10, 10)\n",
        "        )"
      ],
      "metadata": {
        "id": "fVWc-WuCVYgj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize_flow(\n",
        "#     4,\n",
        "#     train_flow\n",
        "# )\n",
        "\n",
        "# visualize_flow(\n",
        "#     4, \n",
        "#     val_flow\n",
        "# )"
      ],
      "metadata": {
        "id": "6nhgqxPEVteF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model preparation"
      ],
      "metadata": {
        "id": "oCI6YguP-OCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_cnn(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters = 96, kernel_size = (11, 11), strides = 4, padding = 'valid', activation = 'relu', input_shape = (256, 256, 3)))\n",
        "    model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'valid', data_format = None))\n",
        "\n",
        "    model.add(Conv2D(filters = 96, kernel_size = (6, 6), strides = 4, padding = 'valid', activation = 'relu', input_shape = (256, 256, 3)))\n",
        "    model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2), padding = 'valid', data_format = None))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(10, activation = 'relu'))\n",
        "    model.add(Dense(1, activation= 'sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer = 'sgd',\n",
        "        # optimizer = Adam(learning_rate = 0.001),\n",
        "        metrics = ['accuracy'],\n",
        "        loss = 'binary_crossentropy'\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "V8u5bTMaLanJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_vgg16(input_shape):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(Conv2D(input_shape=(input_shape),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    \n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\", kernel_initializer = 'he_normal'))\n",
        "    model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "    \n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(units=4096,activation=\"relu\"))\n",
        "    model.add(Dense(units=4096,activation=\"relu\"))\n",
        "    model.add(Dense(units=1, activation=\"sigmoid\"))\n",
        "\n",
        "    model.compile(\n",
        "        metrics = 'accuracy',\n",
        "        loss = 'binary_crossentropy',\n",
        "        optimizer = 'sgd'\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "XYNwXD6CMFrL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def construct_model(name, input_shape):\n",
        "    if name == 'CNN':\n",
        "        return construct_cnn(input_shape)\n",
        "\n",
        "    if name == 'VGG16':\n",
        "        return construct_vgg16(input_shape)"
      ],
      "metadata": {
        "id": "IhAF-GLDW6rZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_steps(flow):\n",
        "    return flow.n // flow.batch_size\n",
        "\n",
        "train_steps = calc_steps(train_flow)\n",
        "val_steps = calc_steps(val_flow)\n",
        "test_steps = calc_steps(test_flow)\n",
        "\n",
        "\n",
        "def fit_models(models_dict, stopper, epochs = 50):\n",
        "    histories = {}\n",
        "    for model_name, model in models_dict.items():\n",
        "        print(f'fitting {model_name}')\n",
        "\n",
        "        histories[model_name] = model.fit(\n",
        "            train_flow,\n",
        "            steps_per_epoch = train_steps,\n",
        "\n",
        "            validation_data = val_flow,\n",
        "            validation_steps = val_steps,\n",
        "\n",
        "            epochs = epochs,\n",
        "            callbacks = [stopper]\n",
        "        )\n",
        "    return histories"
      ],
      "metadata": {
        "id": "Mw59BEVybM8h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'CNN': construct_model('CNN', input_shape = (target_shape[0], target_shape[1], 3)),\n",
        "    'VGG16': construct_model('VGG16', input_shape = (target_shape[0], target_shape[1], 3))\n",
        "}"
      ],
      "metadata": {
        "id": "KPtonN9z8WVR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopper = EarlyStopping(\n",
        "    monitor = 'val_loss',\n",
        "    mode = 'min',\n",
        "    patience = 3\n",
        ")\n",
        "\n",
        "histories = fit_models(\n",
        "    {'CNN': models['CNN']},\n",
        "    stopper = early_stopper,\n",
        "    epochs = 3\n",
        ")"
      ],
      "metadata": {
        "id": "m3npgm3wPXUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa206d28-e3b8-4d95-f321-2dba4eced9f8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting CNN\n",
            "Epoch 1/3\n",
            "128/128 [==============================] - 753s 6s/step - loss: 0.6408 - accuracy: 0.6315 - val_loss: 0.5552 - val_accuracy: 0.7612\n",
            "Epoch 2/3\n",
            "128/128 [==============================] - 36s 279ms/step - loss: 0.5631 - accuracy: 0.7263 - val_loss: 0.5258 - val_accuracy: 0.7522\n",
            "Epoch 3/3\n",
            "128/128 [==============================] - 36s 280ms/step - loss: 0.5136 - accuracy: 0.7713 - val_loss: 0.4919 - val_accuracy: 0.7768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Another model"
      ],
      "metadata": {
        "id": "-_KYzfWdK4_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "histories_vgg16 = fit_models(\n",
        "    {'VGG16': models['VGG16']},\n",
        "    stopper = early_stopper,\n",
        "    epochs = 2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "orgIRHggPtvf",
        "outputId": "08e553d3-e910-4537-b213-fa2a70de6b6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fitting VGG16\n",
            "Epoch 1/5\n",
            "  9/128 [=>............................] - ETA: 36:36 - loss: 0.9175 - accuracy: 0.5556"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0640650ec650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m{\u001b[0m\u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'VGG16'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstopper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearly_stopper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-31-db1fcce19a02>\u001b[0m in \u001b[0;36mfit_models\u001b[0;34m(models_dict, stopper, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstopper\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving models"
      ],
      "metadata": {
        "id": "AA44WQs4Sb9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_models(models_dict):\n",
        "\n",
        "    for model_name, model in models_dict.items():\n",
        "        model.save(\n",
        "            f'{DataProperties.model_save_dir}{model_name}'\n",
        "        )\n",
        "\n",
        "save_models(\n",
        "    {\n",
        "        'CNN': models['CNN']\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssEPWz0mSdUX",
        "outputId": "7d1e3724-c20e-49f9-ebff-60ccce8574db"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/ML/Unox/1/Models//CNN/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save histories"
      ],
      "metadata": {
        "id": "czqhrXZlWnSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_histories(hist_dict, save_dir):\n",
        "    for model_name, hist in hist_dict.items():\n",
        "        df = pd.DataFrame(hist.history)\n",
        "        df.to_csv(f'{save_dir}{model_name}_history.csv')\n",
        "\n",
        "save_histories(\n",
        "    histories,\n",
        "    save_dir = DataProperties.histories_dir\n",
        ")"
      ],
      "metadata": {
        "id": "2ST8FHomWyHL"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}